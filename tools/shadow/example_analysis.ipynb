{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shadow Device Comparison Analysis\n",
    "\n",
    "This notebook demonstrates the workflow for analyzing shadow device logs and comparing them to production device outputs.\n",
    "\n",
    "## Setup\n",
    "\n",
    "First, let's import the necessary modules and check for dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Shadow device tools\n",
    "from openpilot.tools.shadow.comparison_logger import ComparisonLogger, FrameData\n",
    "from openpilot.tools.shadow.align import LogAligner, validate_alignment\n",
    "from openpilot.tools.shadow.metrics import compute_all_metrics, format_report_markdown\n",
    "\n",
    "# Visualization\n",
    "try:\n",
    "    from openpilot.tools.shadow.visualize import (\n",
    "        plot_time_series,\n",
    "        plot_error_histogram,\n",
    "        plot_control_heatmap,\n",
    "        plot_correlation_scatter,\n",
    "        plot_event_timeline,\n",
    "        plot_summary_dashboard,\n",
    "        MATPLOTLIB_AVAILABLE\n",
    "    )\n",
    "    import matplotlib.pyplot as plt\n",
    "    print(\"Visualization libraries available\")\n",
    "except ImportError:\n",
    "    MATPLOTLIB_AVAILABLE = False\n",
    "    print(\"Visualization not available - install matplotlib: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate Sample Data\n",
    "\n",
    "For this example, we'll generate synthetic shadow and production logs.\n",
    "In real usage, you would load logs from `/data/shadow_logs/` on your devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import math\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "def generate_sample_frames(device_id: str, n_frames: int = 1000, noise_level: float = 0.05) -> list[FrameData]:\n",
    "    \"\"\"Generate sample frames simulating a drive with steering and acceleration.\"\"\"\n",
    "    frames = []\n",
    "    base_time = time.time()\n",
    "    \n",
    "    for i in range(n_frames):\n",
    "        # Simulate a winding road with varying speed\n",
    "        t = i / 100.0  # 100 Hz\n",
    "        \n",
    "        # Base steering: sinusoidal curve\n",
    "        base_steer = 0.3 * math.sin(t * 0.5) + 0.1 * math.sin(t * 1.5)\n",
    "        # Base acceleration: varies with road curvature\n",
    "        base_accel = 0.5 - 0.3 * abs(base_steer)\n",
    "        \n",
    "        # Add device-specific noise\n",
    "        steer = base_steer + random.gauss(0, noise_level)\n",
    "        accel = base_accel + random.gauss(0, noise_level * 0.5)\n",
    "        \n",
    "        # Generate events occasionally\n",
    "        events = []\n",
    "        if abs(steer) > 0.25 and random.random() < 0.1:\n",
    "            events.append(\"sharpCurve\")\n",
    "        if accel < 0 and random.random() < 0.05:\n",
    "            events.append(\"braking\")\n",
    "        \n",
    "        frame = FrameData(\n",
    "            frame_id=i,\n",
    "            timestamp_mono=base_time + t,\n",
    "            timestamp_gps=base_time + t + random.gauss(0, 0.001),  # Small GPS jitter\n",
    "            controls={\n",
    "                \"steer_torque\": steer,\n",
    "                \"accel\": accel,\n",
    "                \"steering_angle_deg\": steer * 45,\n",
    "            },\n",
    "            model_outputs={\n",
    "                \"desired_curvature\": base_steer * 0.01,\n",
    "            },\n",
    "            state={\n",
    "                \"v_ego\": 25.0 + accel * 5,\n",
    "                \"a_ego\": accel,\n",
    "                \"lat_active\": True,\n",
    "                \"long_active\": True,\n",
    "            },\n",
    "            events=events,\n",
    "        )\n",
    "        frames.append(frame)\n",
    "    \n",
    "    return frames\n",
    "\n",
    "# Generate sample data\n",
    "print(\"Generating sample shadow device frames...\")\n",
    "shadow_frames = generate_sample_frames(\"shadow\", n_frames=1000, noise_level=0.05)\n",
    "\n",
    "print(\"Generating sample production device frames...\")\n",
    "production_frames = generate_sample_frames(\"production\", n_frames=1000, noise_level=0.03)\n",
    "\n",
    "print(f\"Shadow frames: {len(shadow_frames)}\")\n",
    "print(f\"Production frames: {len(production_frames)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Align Logs\n",
    "\n",
    "The `LogAligner` synchronizes frames from both devices using GPS timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligner = LogAligner()\n",
    "\n",
    "# auto_align tries GPS first, then frame ID, then timestamp\n",
    "result = aligner.auto_align(shadow_frames, production_frames)\n",
    "\n",
    "print(f\"Alignment method: {result.method}\")\n",
    "print(f\"Aligned pairs: {len(result.pairs)}\")\n",
    "print(f\"Shadow-only frames: {len(result.shadow_only)}\")\n",
    "print(f\"Production-only frames: {len(result.production_only)}\")\n",
    "print(f\"Mean time offset: {result.mean_time_offset_ms:.2f} ms\")\n",
    "print(f\"Alignment quality: {result.alignment_quality:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Alignment Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = validate_alignment(result)\n",
    "\n",
    "print(\"Alignment Validation\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in validation.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Comparison Metrics\n",
    "\n",
    "Now we compute detailed metrics comparing shadow and production outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = compute_all_metrics(result)\n",
    "\n",
    "# Display summary\n",
    "print(\"Control Metrics\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"Steer RMSE: {report.control_metrics.steer_rmse:.4f}\")\n",
    "print(f\"Steer MAE: {report.control_metrics.steer_mae:.4f}\")\n",
    "print(f\"Steer Max Error: {report.control_metrics.steer_max_error:.4f}\")\n",
    "print(f\"Accel RMSE: {report.control_metrics.accel_rmse:.4f}\")\n",
    "print(f\"Accel MAE: {report.control_metrics.accel_mae:.4f}\")\n",
    "print(f\"Accel Max Error: {report.control_metrics.accel_max_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Markdown Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_report = format_report_markdown(report)\n",
    "print(markdown_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations\n",
    "\n",
    "Let's create visualizations to understand the differences between devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    # Enable inline plotting\n",
    "    %matplotlib inline\n",
    "    \n",
    "    # Time series comparison\n",
    "    fig = plot_time_series(result.pairs, \"steer\", title=\"Steering Comparison\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping visualizations - matplotlib not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    # Error distribution\n",
    "    fig = plot_error_histogram(result.pairs, \"steer\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    # Correlation scatter\n",
    "    fig = plot_correlation_scatter(result.pairs, \"steer\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    # Control heatmap\n",
    "    fig = plot_control_heatmap(result.pairs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    # Event timeline\n",
    "    fig = plot_event_timeline(result.pairs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MATPLOTLIB_AVAILABLE:\n",
    "    fig = plot_summary_dashboard(result, report)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Algorithm Harness Integration\n",
    "\n",
    "Shadow logs can be imported into the algorithm test harness for replay testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpilot.selfdrive.controls.lib.tests.algorithm_harness.shadow_import import (\n",
    "    import_shadow_log,\n",
    "    compare_shadow_to_harness,\n",
    "    format_shadow_comparison_report,\n",
    ")\n",
    "\n",
    "# Convert shadow frames to harness scenario\n",
    "scenario = import_shadow_log(\n",
    "    shadow_frames,\n",
    "    name=\"sample_drive\",\n",
    "    mode=\"lateral\",\n",
    ")\n",
    "\n",
    "print(f\"Scenario: {scenario.name}\")\n",
    "print(f\"States: {len(scenario.states)}\")\n",
    "print(f\"Description: {scenario.description}\")\n",
    "print(f\"Metadata: {scenario.metadata}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate Harness Outputs\n",
    "\n",
    "In practice, you would run an algorithm through the harness.\n",
    "Here we simulate outputs for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate harness outputs (in practice, these come from running an algorithm)\n",
    "harness_outputs = [\n",
    "    f.controls.get(\"steer_torque\", 0.0) * 0.98 + random.gauss(0, 0.02)  # Simulated algorithm output\n",
    "    for f in shadow_frames\n",
    "]\n",
    "\n",
    "# Compare\n",
    "metrics = compare_shadow_to_harness(shadow_frames, harness_outputs, mode=\"lateral\")\n",
    "\n",
    "print(\"Shadow vs Harness Metrics\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in metrics.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate formatted report\n",
    "harness_report = format_shadow_comparison_report(metrics, \"SimulatedAlgorithm\")\n",
    "print(harness_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Loading Real Logs\n",
    "\n",
    "When working with real data, use the `ComparisonLogger` to load segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Load logs from device\n",
    "# shadow_frames = ComparisonLogger.load_segment(\"/data/shadow_logs/segment_001\")\n",
    "# production_frames = ComparisonLogger.load_segment(\"/data/production_logs/segment_001\")\n",
    "\n",
    "print(\"To load real logs, use:\")\n",
    "print(\"  shadow_frames = ComparisonLogger.load_segment('/data/shadow_logs/segment_001')\")\n",
    "print(\"  production_frames = ComparisonLogger.load_segment('/data/production_logs/segment_001')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Log Alignment** - Synchronizing frames from shadow and production devices using GPS timestamps\n",
    "2. **Metric Computation** - Calculating RMSE, MAE, and other comparison metrics\n",
    "3. **Visualization** - Creating time series, histograms, scatter plots, and dashboards\n",
    "4. **Algorithm Harness** - Importing shadow logs for replay testing\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Capture real logs on your shadow device\n",
    "- Compare different algorithm versions\n",
    "- Identify scenarios where devices diverge\n",
    "- Use the harness to test algorithm changes on real data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
